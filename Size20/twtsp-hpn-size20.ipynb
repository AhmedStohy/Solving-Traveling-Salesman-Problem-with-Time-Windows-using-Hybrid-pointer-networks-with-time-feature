{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport time\nimport argparse\n\nimport os\nimport datetime\n\nfrom torch.distributions.categorical import Categorical\nfrom scipy.spatial import distance\n# visualization \n%matplotlib inline\nfrom IPython.display import set_matplotlib_formats, clear_output\nset_matplotlib_formats('png2x','pdf')\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\ntry: \n    import networkx as nx\n    from scipy.spatial.distance import pdist, squareform\nexcept:\n    pass\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\ndevice = torch.device(\"cpu\"); gpu_id = -1 # select CPU\n\ngpu_id = '0' # select a single GPU  \n#gpu_id = '2,3' # select multiple GPUs  \nos.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)  \nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print('GPU name: {:s}, gpu_id: {:s}'.format(torch.cuda.get_device_name(0),gpu_id))   \n    \nprint(device)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-05T15:29:03.793257Z","iopub.execute_input":"2021-09-05T15:29:03.793631Z","iopub.status.idle":"2021-09-05T15:29:05.625596Z","shell.execute_reply.started":"2021-09-05T15:29:03.793552Z","shell.execute_reply":"2021-09-05T15:29:05.624783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Architecture","metadata":{}},{"cell_type":"code","source":"import math\nimport numpy as np\nimport torch.nn.functional as F\nimport random\nimport torch.optim as optim\nfrom torch.autograd import Variable\nfrom torch.optim import lr_scheduler\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm_notebook\n\nclass Transformer_encoder_net(nn.Module):\n    \"\"\"\n    Encoder network based on self-attention transformer\n    Inputs :  \n      h of size      (bsz, nb_nodes+1, dim_emb)    batch of input cities\n    Outputs :  \n      h of size      (bsz, nb_nodes+1, dim_emb)    batch of encoded cities\n      score of size  (bsz, nb_nodes+1, nb_nodes+1) batch of attention scores\n    \"\"\"\n    \n    def __init__(self, nb_layers, dim_emb, nb_heads, dim_ff, batchnorm):\n        super(Transformer_encoder_net, self).__init__()\n        assert dim_emb == nb_heads* (dim_emb//nb_heads) # check if dim_emb is divisible by nb_heads\n        self.MHA_layers = nn.ModuleList( [nn.MultiheadAttention(dim_emb, nb_heads) for _ in range(nb_layers)] )\n        self.linear1_layers = nn.ModuleList( [nn.Linear(dim_emb, dim_ff) for _ in range(nb_layers)] )\n        self.linear2_layers = nn.ModuleList( [nn.Linear(dim_ff, dim_emb) for _ in range(nb_layers)] )   \n        if batchnorm:\n            self.norm1_layers = nn.ModuleList( [nn.BatchNorm1d(dim_emb) for _ in range(nb_layers)] )\n            self.norm2_layers = nn.ModuleList( [nn.BatchNorm1d(dim_emb) for _ in range(nb_layers)] )\n        else:\n            self.norm1_layers = nn.ModuleList( [nn.LayerNorm(dim_emb) for _ in range(nb_layers)] )\n            self.norm2_layers = nn.ModuleList( [nn.LayerNorm(dim_emb) for _ in range(nb_layers)] )\n        self.nb_layers = nb_layers\n        self.nb_heads = nb_heads\n        self.batchnorm = batchnorm\n        \n    def forward(self, h):      \n        # PyTorch nn.MultiheadAttention requires input size (seq_len, bsz, dim_emb) \n        h = h.transpose(0,1) # size(h)=(nb_nodes, bsz, dim_emb)  \n        # L layers\n        for i in range(self.nb_layers):\n            h_rc = h # residual connection, size(h_rc)=(nb_nodes, bsz, dim_emb)\n            h, score = self.MHA_layers[i](h, h, h) # size(h)=(nb_nodes, bsz, dim_emb), size(score)=(bsz, nb_nodes, nb_nodes)\n            # add residual connection\n            \n            h = h_rc + h # size(h)=(nb_nodes, bsz, dim_emb)\n            if self.batchnorm:\n                # Pytorch nn.BatchNorm1d requires input size (bsz, dim, seq_len)\n                h = h.permute(1,2,0).contiguous() # size(h)=(bsz, dim_emb, nb_nodes)\n                h = self.norm1_layers[i](h)       # size(h)=(bsz, dim_emb, nb_nodes)\n                h = h.permute(2,0,1).contiguous() # size(h)=(nb_nodes, bsz, dim_emb)\n            else:\n                h = self.norm1_layers[i](h)       # size(h)=(nb_nodes, bsz, dim_emb) \n            # feedforward\n            h_rc = h # residual connection\n            h = self.linear2_layers[i](torch.relu(self.linear1_layers[i](h)))\n            h = h_rc + h # size(h)=(nb_nodes, bsz, dim_emb)\n            if self.batchnorm:\n                h = h.permute(1,2,0).contiguous() # size(h)=(bsz, dim_emb, nb_nodes)\n                h = self.norm2_layers[i](h)       # size(h)=(bsz, dim_emb, nb_nodes)\n                h = h.permute(2,0,1).contiguous() # size(h)=(nb_nodes, bsz, dim_emb)\n            else:\n                h = self.norm2_layers[i](h) # size(h)=(nb_nodes, bsz, dim_emb)\n        # Transpose h\n        h = h.transpose(0,1) # size(h)=(bsz, nb_nodes, dim_emb)\n        return h, score\n\nclass Attention(nn.Module):\n    def __init__(self, n_hidden):\n        super(Attention, self).__init__()\n        \n        self.size = 0\n        self.batch_size = 0\n        self.dim = n_hidden\n        \n        v  = torch.FloatTensor(n_hidden).cuda()\n        self.v  = nn.Parameter(v)\n        self.v.data.uniform_(-1/math.sqrt(n_hidden), 1/math.sqrt(n_hidden))\n        \n        # parameters for pointer attention\n        self.Wref = nn.Linear(n_hidden, n_hidden)\n        self.Wq = nn.Linear(n_hidden, n_hidden)\n    \n    \n    def forward(self, q, ref):       # query and reference\n        self.batch_size = q.size(0)\n        self.size = int(ref.size(0) / self.batch_size)\n        q = self.Wq(q)     # (B, dim)\n        ref = self.Wref(ref)\n        ref = ref.view(self.batch_size, self.size, self.dim)  # (B, size, dim)\n        \n        q_ex = q.unsqueeze(1).repeat(1, self.size, 1) # (B, size, dim)\n        # v_view: (B, dim, 1)\n        v_view = self.v.unsqueeze(0).expand(self.batch_size, self.dim).unsqueeze(2)\n        \n        # (B, size, dim) * (B, dim, 1)\n        u = torch.bmm(torch.tanh(q_ex + ref), v_view).squeeze(2)\n        \n        return u, ref\n    \nclass LSTM(nn.Module):\n    def __init__(self, n_hidden):\n        super(LSTM, self).__init__()\n        \n        # parameters for input gate\n        self.Wxi = nn.Linear(n_hidden, n_hidden)    # W(xt)\n        self.Whi = nn.Linear(n_hidden, n_hidden)    # W(ht)\n        self.wci = nn.Linear(n_hidden, n_hidden)    # w(ct)\n        \n        # parameters for forget gate\n        self.Wxf = nn.Linear(n_hidden, n_hidden)    # W(xt)\n        self.Whf = nn.Linear(n_hidden, n_hidden)    # W(ht)\n        self.wcf = nn.Linear(n_hidden, n_hidden)    # w(ct)\n        \n        # parameters for cell gate\n        self.Wxc = nn.Linear(n_hidden, n_hidden)    # W(xt)\n        self.Whc = nn.Linear(n_hidden, n_hidden)    # W(ht)\n        \n        # parameters for forget gate\n        self.Wxo = nn.Linear(n_hidden, n_hidden)    # W(xt)\n        self.Who = nn.Linear(n_hidden, n_hidden)    # W(ht)\n        self.wco = nn.Linear(n_hidden, n_hidden)    # w(ct)\n    \n    \n    def forward(self, x, h, c):       # query and reference\n        \n        # input gate\n        i = torch.sigmoid(self.Wxi(x) + self.Whi(h) + self.wci(c))\n        # forget gate\n        f = torch.sigmoid(self.Wxf(x) + self.Whf(h) + self.wcf(c))\n        # cell gate\n        c = f * c + i * torch.tanh(self.Wxc(x) + self.Whc(h))\n        # output gate\n        o = torch.sigmoid(self.Wxo(x) + self.Who(h) + self.wco(c))\n        \n        h = o * torch.tanh(c)\n        \n        return h, c\n\nclass HPN(nn.Module):\n    def __init__(self, n_feature, n_hidden):\n\n        super(HPN, self).__init__()\n        self.city_size = 0\n        self.batch_size = 0\n        self.dim = n_hidden\n        \n        # lstm for first turn\n        #self.lstm0 = nn.LSTM(n_hidden, n_hidden)\n        \n        # pointer layer\n        self.pointer = Attention(n_hidden)\n        self.TransPointer = Attention(n_hidden)\n        \n        # lstm encoder\n        self.encoder = LSTM(n_hidden)\n        \n        # trainable first hidden input\n        h0 = torch.FloatTensor(n_hidden)\n        c0 = torch.FloatTensor(n_hidden)\n        \n        # trainable latent variable coefficient\n        alpha = torch.ones(1).cuda()\n        \n        self.h0 = nn.Parameter(h0)\n        self.c0 = nn.Parameter(c0)\n        \n        self.alpha = nn.Parameter(alpha)\n        self.h0.data.uniform_(-1/math.sqrt(n_hidden), 1/math.sqrt(n_hidden))\n        self.c0.data.uniform_(-1/math.sqrt(n_hidden), 1/math.sqrt(n_hidden))\n        \n        r1 = torch.ones(1)\n        r2 = torch.ones(1)\n        r3 = torch.ones(1)\n        self.r1 = nn.Parameter(r1)\n        self.r2 = nn.Parameter(r2)\n        self.r3 = nn.Parameter(r3)\n        \n        # embedding\n        self.embedding_x = nn.Linear(n_feature, n_hidden)\n        self.embedding_all = nn.Linear(n_feature, n_hidden)\n        self.Transembedding_all = Transformer_encoder_net(6, 128, 8, 512, batchnorm=True)\n        \n        # vector to start decoding \n        self.start_placeholder = nn.Parameter(torch.randn(n_hidden))\n        \n        # weights for GNN\n        self.W1 = nn.Linear(n_hidden, n_hidden)\n        self.W2 = nn.Linear(n_hidden, n_hidden)\n        self.W3 = nn.Linear(n_hidden, n_hidden)\n        \n        # aggregation function for GNN\n        self.agg_1 = nn.Linear(n_hidden, n_hidden)\n        self.agg_2 = nn.Linear(n_hidden, n_hidden)\n        self.agg_3 = nn.Linear(n_hidden, n_hidden)\n    \n    \n    def forward(self,context,Transcontext, x, X_all, mask, h=None, c=None, latent=None):\n        '''\n        Inputs (B: batch size, size: city size, dim: hidden dimension)\n        \n        x: current city coordinate (B, 2)\n        X_all: all cities' cooridnates (B, size, 2)\n        mask: mask visited cities\n        h: hidden variable (B, dim)\n        c: cell gate (B, dim)\n        latent: latent pointer vector from previous layer (B, size, dim)\n        \n        Outputs\n        \n        softmax: probability distribution of next city (B, size)\n        h: hidden variable (B, dim)\n        c: cell gate (B, dim)\n        latent_u: latent pointer vector for next layer\n        '''\n        \n        self.batch_size = X_all.size(0)\n        self.city_size = X_all.size(1)\n        \n\n        # the weights share across all the cities\n        # Embedd All Cities\n        if h is None or c is None:\n            x          = self.start_placeholder    \n            context = self.embedding_all(X_all)\n            Transcontext,_ = self.Transembedding_all(context)\n            \n            # =============================\n            # graph neural network encoder\n            # =============================\n\n            # (B, size, dim)\n            context = context.reshape(-1, self.dim)\n            Transcontext = Transcontext.reshape(-1, self.dim)\n\n            context = self.r1 * self.W1(context)\\\n                + (1-self.r1) * F.relu(self.agg_1(context/(self.city_size-1)))\n\n            context = self.r2 * self.W2(context)\\\n                + (1-self.r2) * F.relu(self.agg_2(context/(self.city_size-1)))\n\n            context = self.r3 * self.W3(context)\\\n                + (1-self.r3) * F.relu(self.agg_3(context/(self.city_size-1)))\n            h0 = self.h0.unsqueeze(0).expand(self.batch_size, self.dim)\n            c0 = self.c0.unsqueeze(0).expand(self.batch_size, self.dim)\n\n            h0 = h0.unsqueeze(0).contiguous()\n            c0 = c0.unsqueeze(0).contiguous()\n            \n            # let h0, c0 be the hidden variable of first turn\n            h = h0.squeeze(0)\n            c = c0.squeeze(0)\n        else:\n            x          = self.embedding_x(x)\n        # LSTM encoder\n        h, c = self.encoder(x, h, c)\n        # query vector\n        q = h\n        # pointer\n        u1, _ = self.pointer(q, context)\n        u2 ,_ = self.TransPointer(q,Transcontext)\n        u = u1 + u2\n        latent_u = u.clone()\n        u = 10 * torch.tanh(u) + mask\n        \n        if latent is not None:\n            u += self.alpha * latent\n    \n        return context,Transcontext,F.softmax(u, dim=1), h, c, latent_u","metadata":{"execution":{"iopub.status.busy":"2021-09-05T15:29:05.627043Z","iopub.execute_input":"2021-09-05T15:29:05.627287Z","iopub.status.idle":"2021-09-05T15:29:05.673357Z","shell.execute_reply.started":"2021-09-05T15:29:05.627264Z","shell.execute_reply":"2021-09-05T15:29:05.67257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Generation","metadata":{}},{"cell_type":"code","source":"'''\ngenerate training data\n'''\nDataGen  = HPN(n_feature=2, n_hidden=128)\nDataGen = DataGen.to(device)\nDataGen.eval()\n# Upload checkpoint For pre-trained model \"HPN for TSP\"\ncheckpoint_file = \"../input/checkpoint_21-09-05--08-53-44-n50-gpu0.pkl\"\ncheckpoint = torch.load(checkpoint_file, map_location=device)\nDataGen.load_state_dict(checkpoint['model_baseline'])\nprint(\"Done\")\ndel checkpoint\n\ndef ModelSolution(B,size,Critic):\n    zero_to_bsz = torch.arange(B, device=device) # [0,1,...,bsz-1]\n    X = torch.rand(B, size, 2,device = device)\n    mask = torch.zeros(B,size,device = device)\n    solution = []    \n    Y = X.view(B, size, 2)           # to the same batch size\n    x = Y[:,0,:]\n    h = None\n    c = None\n    context = None\n    Transcontext = None\n    \n    with torch.no_grad():\n        for k in range(size):\n            context,Transcontext,output, h, c, _ = Critic(context,Transcontext,x=x, X_all=X, h=h, c=c, mask=mask)\n            idx = torch.argmax(output, dim=1)\n            x = Y[zero_to_bsz, idx.data]\n            solution.append(x.cpu().numpy())\n            mask[zero_to_bsz, idx.data] += -np.inf\n        graph = torch.tensor(solution).permute(1,0,2)# Shape = (B,size,2)\n    return graph\n\ndef generate_data(model,B=512, size=50):\n    #X = np.zeros([B, size, 4])  # xi, yi, ei, li, ci\n    solutions = torch.zeros(B,device = 'cuda')\n    route = [x for x in range(size)] + [0]\n    route = torch.tensor(route).unsqueeze(0).repeat(B,1)\n    X = ModelSolution(B,size,model).to('cuda')\n    \n    arange_vec = torch.arange(B, device=X.device)\n    ColAdded = torch.zeros((B,size,2),device = X.device)\n    X = torch.cat((X,ColAdded),dim = 2).to(X.device)\n    X[arange_vec,0,3] = 2 * torch.rand(B,device = X.device)  # l0 = rand\n    first_cities = X[arange_vec, route[:,0], :2] # size(first_cities)=(bsz,2) \n    previous_cities = first_cities\n    cur_time = torch.zeros(B, device=X.device)\n    tour_len = torch.zeros(B, device=X.device)\n    zeros = torch.zeros(B,device = X.device)\n    with torch.no_grad():\n        for k in range(1, size):\n            # generate data with approximate solutions\n            current_cities = X[arange_vec, route[:,k], :2] \n            cur_time += torch.sum( (current_cities - previous_cities)**2 , dim=1 )**0.5\n            tour_len += torch.sum( (current_cities - previous_cities)**2 , dim=1 )**0.5\n            \n            previous_cities = current_cities\n            X[arange_vec,k,2] = torch.maximum(zeros, (cur_time - 2*torch.rand(B,device = X.device)))  # entering time 0<= ei <= cur_time\n            X[arange_vec,k,3] = cur_time + 2*torch.rand(B,device = X.device) + 1  # leaving time li >= cur_time\n        \n        tour_len += torch.sum( (current_cities - first_cities)**2 , dim=1 )**0.5   \n        solutions += tour_len\n        \n    X = np.array(X.cpu().numpy())\n    np.random.shuffle(X)\n    X = torch.tensor(X).to('cuda')\n    \n    return X, solutions","metadata":{"execution":{"iopub.status.busy":"2021-09-05T15:29:05.675272Z","iopub.execute_input":"2021-09-05T15:29:05.67562Z","iopub.status.idle":"2021-09-05T15:29:10.51477Z","shell.execute_reply.started":"2021-09-05T15:29:05.675584Z","shell.execute_reply":"2021-09-05T15:29:10.51313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"size = 20\nlearn_rate = 1e-4    # learning rate\nB = 512              # batch_size\nTOL  =  1e-3\nB_val = 1000           # validation size\nB_valLoop = 20\nsteps = 2500 # training steps\nn_epoch = 100       # epochs\n\nprint('=========================')\nprint('prepare to train')\nprint('=========================')\nprint('Hyperparameters:')\nprint('size', size)\nprint('learning rate', learn_rate)\nprint('batch size', B)\nprint('validation size', B_val)\nprint('steps', steps)\nprint('epoch', n_epoch)\nprint('=========================')\n\n###################\n# Instantiate a training network and a baseline network\n###################\n\ntry: \n    del ActorLow # remove existing model\n    del CriticLow # remove existing model\nexcept:\n    pass\n\nActorLow  = HPN(n_feature=4, n_hidden=128)\nCriticLow = HPN(n_feature=4, n_hidden=128)\noptimizer = optim.Adam(ActorLow.parameters(), lr=learn_rate)\n\n# Putting Critic model on the eval mode\nActorLow = ActorLow.to(device)\nCriticLow = CriticLow.to(device)\n\nCriticLow.eval()\n\n########################\n# Remember to first initialize the model and optimizer, then load the dictionary locally.\n#######################\nepoch_ckpt = 0\ntot_time_ckpt = 0\nval_mean = []\nval_std = []\nval_accuracy = []\nplot_performance_train = []\nplot_performance_baseline = []\n#********************************************# Uncomment these lines to re-start training with saved checkpoint #********************************************#\n\"\"\"\ncheckpoint_file = \"../input/nonhiersize20/checkpoint_21-09-05--08-55-01-n50-gpu0.pkl\"\ncheckpoint = torch.load(checkpoint_file, map_location=device)\nepoch_ckpt = checkpoint['epoch'] + 1\ntot_time_ckpt = checkpoint['tot_time']\nplot_performance_train = checkpoint['plot_performance_train']\nplot_performance_baseline = checkpoint['plot_performance_baseline']\nCriticLow.load_state_dict(checkpoint['model_baseline'])\nActorLow.load_state_dict(checkpoint['model_train'])\noptimizer.load_state_dict(checkpoint['optimizer'])\n\nprint('Re-start training with saved checkpoint file={:s}\\n  Checkpoint at epoch= {:d} and time={:.3f}min\\n'.format(checkpoint_file,epoch_ckpt-1,tot_time_ckpt/60))\ndel checkpoint\n\"\"\"\n#*********************************************# Uncomment these lines to re-start training with saved checkpoint #********************************************#\n\n\n###################\n#  Main training loop \n###################\nstart_training_time = time.time()\ntime_stamp = datetime.datetime.now().strftime(\"%y-%m-%d--%H-%M-%S\")\n\nC = 0     # baseline\nR = 0     # reward\n\nzero_to_bsz = torch.arange(B, device=device) # [0,1,...,bsz-1]\nzero_to_bsz_val = torch.arange(B_val, device=device) # [0,1,...,bsz-1]\nfor epoch in range(0,n_epoch):\n    \n    # re-start training with saved checkpoint\n    epoch += epoch_ckpt\n\n    ###################\n    # Train model for one epoch\n    ###################\n    \n    start = time.time()\n    ActorLow.train()\n    for i in range(1,steps+1):\n        \n        X, _ = generate_data(DataGen,B=B, size=size)\n\n        Enter = X[:,:,2]   # Entering time\n        Leave = X[:,:,3]   # Leaving time\n        mask = torch.zeros(B,size).cuda()\n    \n        R = 0\n        logprobs = 0\n        reward = 0\n        \n        time_wait = torch.zeros(B).cuda()\n        time_penalty = torch.zeros(B).cuda()\n        total_time_penalty_train = torch.zeros(B).cuda()\n        total_time_cost_train = torch.zeros(B).cuda()\n        total_time_wait_train = torch.zeros(B).cuda()\n\n        \n        # X = X.view(B,size,3)\n        # Time = Time.view(B,size)\n\n        x = X[:,0,:]\n        h = None\n        c = None\n        \n        context = None\n        Transcontext = None \n        #Actor Sampling phase\n        for k in range(size):\n            context,Transcontext,output, h, c, _ = ActorLow(context,Transcontext,x=x, X_all=X, h=h, c=c, mask=mask)            \n            sampler = torch.distributions.Categorical(output)\n            idx = sampler.sample()\n            \n            y_cur = X[zero_to_bsz, idx.data].clone()\n            if k == 0:\n                y_ini = y_cur.clone()\n            if k > 0:\n                reward = torch.norm(y_cur[:,:2] - y_pre[:,:2], dim=1)\n                \n            y_pre = y_cur.clone()\n            x = X[zero_to_bsz, idx.data].clone()\n            \n            R += reward\n            total_time_cost_train += reward\n            # enter time\n            enter = Enter[zero_to_bsz, idx.data]\n            leave = Leave[zero_to_bsz, idx.data]\n            \n            # determine the total reward and current enter time\n            time_wait = torch.lt(total_time_cost_train, enter).float()*(enter - total_time_cost_train)  \n            total_time_wait_train += time_wait     # total time cost\n            total_time_cost_train += time_wait\n            time_penalty = torch.lt(leave, total_time_cost_train).float()*10\n            total_time_cost_train += time_penalty\n            total_time_penalty_train += time_penalty\n            logprobs += torch.log(output[zero_to_bsz, idx.data]) \n            \n            mask[zero_to_bsz, idx.data] += -np.inf \n        R += torch.norm(y_cur[:,:2] - y_ini[:,:2], dim=1)\n        total_time_cost_train += torch.norm(y_cur[:,:2] - y_ini[:,:2], dim=1)\n\n       \n       \n        # Critic Baseline phase\n        C = 0\n        baseline = 0\n        mask = torch.zeros(B,size).cuda()        \n        time_wait = torch.zeros(B).cuda()\n        time_penalty = torch.zeros(B).cuda()\n        total_time_penalty_base = torch.zeros(B).cuda()\n        total_time_cost_base = torch.zeros(B).cuda()\n        total_time_wait_base = torch.zeros(B).cuda()\n\n        x = X[:,0,:]\n        h = None\n        c = None\n        \n        context = None\n        Transcontext = None \n\n        # compute tours for baseline without grad\n        with torch.no_grad():\n            for k in range(size):\n                context,Transcontext,output, h, c, _ = CriticLow(context,Transcontext,x=x, X_all=X, h=h, c=c, mask=mask)\n                idx = torch.argmax(output, dim=1) # ----> greedy baseline critic\n                y_cur = X[zero_to_bsz, idx.data].clone()\n                if k == 0:\n                    y_ini = y_cur.clone()\n                if k > 0:\n                    baseline = torch.norm(y_cur[:,:2] - y_pre[:,:2], dim=1)\n\n                y_pre = y_cur.clone()\n                x = X[zero_to_bsz, idx.data].clone()\n\n                C += baseline\n                total_time_cost_base += baseline\n                # enter time\n                enter = Enter[zero_to_bsz, idx.data]\n                leave = Leave[zero_to_bsz, idx.data]\n\n                # determine the total reward and current enter time\n                time_wait = torch.lt(total_time_cost_base, enter).float()*(enter - total_time_cost_base)  \n                total_time_wait_base += time_wait     # total time cost\n                total_time_cost_base += time_wait\n                time_penalty = torch.lt(leave, total_time_cost_base).float()*10\n                total_time_cost_base += time_penalty\n                total_time_penalty_base += time_penalty\n\n                mask[zero_to_bsz, idx.data] += -np.inf \n            C += torch.norm(y_cur[:,:2] - y_ini[:,:2], dim=1)\n            total_time_cost_base += torch.norm(y_cur[:,:2] - y_ini[:,:2], dim=1)\n\n        ###################\n        # Loss and backprop handling \n        ###################\n        \n        loss = torch.mean((total_time_cost_train - total_time_cost_base) * logprobs)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        if i % 50 == 0:\n            print(\"epoch:{}, batch:{}/{},  total time:{}, reward:{}, time:{}\"\n                .format(epoch, i, steps, total_time_cost_train.mean().item(),\n                        R.mean().item(), total_time_wait_train.mean().item()))\n                \n    time_one_epoch = time.time() - start\n    time_tot = time.time() - start_training_time + tot_time_ckpt\n    \n    ###################\n    # Evaluate train model and baseline on 1k random TSP instances\n    ###################\n    \n    ActorLow.eval()\n    mean_tour_length_actor = 0\n    mean_tour_length_critic = 0\n\n    for step in range(0,B_valLoop):\n        # compute tour for model and baseline\n        X, solutions = generate_data(DataGen,B=B, size=size)\n        Enter = X[:,:,2]   # Entering time\n        Leave = X[:,:,3]   # Leaving time\n\n        mask = torch.zeros(B,size).cuda()\n    \n        R = 0\n        reward = 0\n        \n        time_wait = torch.zeros(B).cuda()\n        time_penalty = torch.zeros(B).cuda()\n        total_time_penalty_train = torch.zeros(B).cuda()\n        total_time_cost_train = torch.zeros(B).cuda()\n        total_time_wait_train = torch.zeros(B).cuda()\n\n        \n        # X = X.view(B,size,3)\n        # Time = Time.view(B,size)\n\n        x = X[:,0,:]\n        h = None\n        c = None\n        \n        context = None\n        Transcontext = None \n        #Actor ِGreedy phase\n        with torch.no_grad():\n            for k in range(size):\n                context,Transcontext,output, h, c, _ = ActorLow(context,Transcontext,x=x, X_all=X, h=h, c=c, mask=mask)            \n                idx = torch.argmax(output, dim=1) # ----> greedy baseline critic\n                \n                y_cur = X[zero_to_bsz, idx.data].clone()\n                if k == 0:\n                    y_ini = y_cur.clone()\n                if k > 0:\n                    reward = torch.norm(y_cur[:,:2] - y_pre[:,:2], dim=1)\n\n                y_pre = y_cur.clone()\n                x = X[zero_to_bsz, idx.data].clone()\n\n                R += reward\n                total_time_cost_train += reward\n                # enter time\n                enter = Enter[zero_to_bsz, idx.data]\n                leave = Leave[zero_to_bsz, idx.data]\n\n                # determine the total reward and current enter time\n                time_wait = torch.lt(total_time_cost_train, enter).float()*(enter - total_time_cost_train)  \n                total_time_wait_train += time_wait     # total time cost\n                total_time_cost_train += time_wait\n                \n                time_penalty = torch.lt(leave, total_time_cost_train).float()*10\n                #total_time_cost_train += time_penalty\n                total_time_penalty_train += time_penalty\n\n                mask[zero_to_bsz, idx.data] += -np.inf\n        R += torch.norm(y_cur[:,:2] - y_ini[:,:2], dim=1)\n        total_time_cost_train += torch.norm(y_cur[:,:2] - y_ini[:,:2], dim=1)\n\n       \n       \n        # Critic Baseline phase\n        C = 0\n        baseline = 0\n        mask = torch.zeros(B,size).cuda()        \n        time_wait = torch.zeros(B).cuda()\n        time_penalty = torch.zeros(B).cuda()\n        total_time_penalty_base = torch.zeros(B).cuda()\n        total_time_cost_base = torch.zeros(B).cuda()\n        total_time_wait_base = torch.zeros(B).cuda()\n\n        x = X[:,0,:]\n        h = None\n        c = None\n        \n        context = None\n        Transcontext = None \n\n        # compute tours for baseline without grad\n        with torch.no_grad():\n            for k in range(size):\n                context,Transcontext,output, h, c, _ = CriticLow(context,Transcontext,x=x, X_all=X, h=h, c=c, mask=mask)\n                idx = torch.argmax(output, dim=1) # ----> greedy baseline critic\n                \n                y_cur = X[zero_to_bsz, idx.data].clone()\n                if k == 0:\n                    y_ini = y_cur.clone()\n                if k > 0:\n                    baseline = torch.norm(y_cur[:,:2] - y_pre[:,:2], dim=1)\n\n                y_pre = y_cur.clone()\n                x = X[zero_to_bsz, idx.data].clone()\n\n                C += baseline\n                total_time_cost_base += baseline\n                # enter time\n                enter = Enter[zero_to_bsz, idx.data]\n                leave = Leave[zero_to_bsz, idx.data]\n\n                # determine the total reward and current enter time\n                time_wait = torch.lt(total_time_cost_base, enter).float()*(enter - total_time_cost_base)  \n                total_time_wait_base += time_wait     # total time cost\n                total_time_cost_base += time_wait\n                \n                time_penalty = torch.lt(leave, total_time_cost_base).float()*10\n                #total_time_cost_base += time_penalty\n                total_time_penalty_base += time_penalty\n\n                mask[zero_to_bsz, idx.data] += -np.inf \n                \n        C += torch.norm(y_cur[:,:2] - y_ini[:,:2], dim=1)\n        total_time_cost_base += torch.norm(y_cur[:,:2] - y_ini[:,:2], dim=1)\n        \n        mean_tour_length_actor  += total_time_cost_train.mean().item()\n        mean_tour_length_critic += total_time_cost_base.mean().item()\n        \n    mean_tour_length_actor  =  mean_tour_length_actor  / B_valLoop\n    mean_tour_length_critic =  mean_tour_length_critic / B_valLoop\n\n    # evaluate train model and baseline and update if train model is better\n    update_baseline = mean_tour_length_actor < mean_tour_length_critic\n    print('Avg Actor {} --- Avg Critic {}'.format(mean_tour_length_actor,mean_tour_length_critic))\n    if update_baseline:\n        CriticLow.load_state_dict(ActorLow.state_dict())\n        print('My actor is going on the right road Hallelujah :) Updated')\n        \n    ###################\n    # Valdiation train model and baseline on 1k random TSP instances\n    ###################\n    \n    with torch.no_grad():\n        print(\"optimal upper bound:{}\".format(solutions.mean()))\n        X_val, _ = generate_data(DataGen,B=B_val, size=size)\n        Enter = X_val[:,:,2]   # Entering time\n        Leave = X_val[:,:,3]   # Leaving time\n        mask = torch.zeros(B_val, size).to(device)\n\n        baseline = 0\n        time_wait = torch.zeros(B_val).to(device)\n        time_penalty = torch.zeros(B_val).to(device)\n        total_time_cost = torch.zeros(B_val).to(device)\n        total_time_penalty = torch.zeros(B_val).to(device)\n\n        x = X_val[:,0,:]\n        h = None\n        c = None\n        context = None\n        Transcontext = None \n\n        for k in range(size):\n            context,Transcontext,output, h, c, _ = CriticLow(context,Transcontext,x=x, X_all=X_val, h=h, c=c, mask=mask)\n            idx = torch.argmax(output, dim=1)    # greedy baseline\n            y_cur = X_val[zero_to_bsz_val, idx.data].clone()\n            if k == 0:\n                y_ini = y_cur.clone()\n            if k > 0:\n                baseline = torch.norm(y_cur[:,:2] - y_pre[:,:2], dim=1)\n            y_pre = y_cur.clone()\n            x = X_val[zero_to_bsz_val, idx.data].clone()\n            total_time_cost += baseline\n\n            # enter time\n            enter = Enter[zero_to_bsz_val, idx.data]\n            leave = Leave[zero_to_bsz_val, idx.data]\n\n            # determine the total reward and current enter time\n            time_wait = torch.lt(total_time_cost, enter).float()*(enter - total_time_cost)  \n            total_time_cost += time_wait\n\n            time_penalty = torch.lt(leave, total_time_cost).float()*10\n            total_time_cost += time_penalty\n            total_time_penalty += time_penalty\n            mask[zero_to_bsz_val, idx.data] += -np.inf \n            \n        total_time_cost += torch.norm(y_cur[:,:2] - y_ini[:,:2], dim=1)\n        accuracy = 1 - torch.lt(torch.zeros_like(total_time_penalty), total_time_penalty).sum().float() / total_time_penalty.size(0)\n        print('validation result:{}, accuracy:{}'\n                  .format(total_time_cost.mean().item(), accuracy))\n\n        val_mean.append(total_time_cost.mean().item())\n        val_std.append(total_time_cost.std().item())\n        val_accuracy.append(accuracy)\n\n    # For checkpoint\n    plot_performance_train.append([(epoch+1), mean_tour_length_actor])\n    plot_performance_baseline.append([(epoch+1), mean_tour_length_critic])\n    \n    # Compute optimality gap\n    if size==50: gap_train = mean_tour_length_actor/5.692- 1.0\n    elif size==100: gap_train = mean_tour_length_actor/7.765- 1.0\n    else: gap_train = -1.0\n        \n    # Print and save in txt file\n    mystring_min = 'Epoch: {:d}, epoch time: {:.3f}min, tot time: {:.3f}day, L_actor: {:.3f}, L_critic: {:.3f}, gap_train(%): {:.3f}, update: {}'.format(\n        epoch, time_one_epoch/60, time_tot/86400, mean_tour_length_actor, mean_tour_length_critic, 100 * gap_train, update_baseline)\n    \n    print(mystring_min)\n    print('Save Checkpoints')\n    \n    # Saving checkpoint\n    checkpoint_dir = os.path.join(\"checkpoint\")\n    if not os.path.exists(checkpoint_dir):\n        os.makedirs(checkpoint_dir)\n        \n    torch.save({\n        'epoch': epoch,\n        'time': time_one_epoch,\n        'tot_time': time_tot,\n        'loss': loss.item(),\n        'plot_performance_train': plot_performance_train,\n        'plot_performance_baseline': plot_performance_baseline,\n        'mean_tour_length_val': total_time_penalty,\n        'model_baseline': CriticLow.state_dict(),\n        'model_train': ActorLow.state_dict(),\n        'optimizer': optimizer.state_dict(),\n        }, '{}.pkl'.format(checkpoint_dir + \"/checkpoint_\" + time_stamp + \"-n{}\".format(size) + \"-gpu{}\".format(gpu_id)))","metadata":{"execution":{"iopub.status.busy":"2021-09-05T15:29:10.516461Z","iopub.execute_input":"2021-09-05T15:29:10.51681Z","iopub.status.idle":"2021-09-05T17:09:45.115197Z","shell.execute_reply.started":"2021-09-05T15:29:10.516775Z","shell.execute_reply":"2021-09-05T17:09:45.106146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}